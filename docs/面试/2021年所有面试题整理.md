
[toc]

### 找面试题

### 找答案
【JAVA全栈笔记】https://www.pdai.tech/
【JDK源码】https://gitee.com/TanYuXiao/jdk-source?_from=gitee_search



#### JAVA基础
问题：
* 线程池的核心参数与流程，任务队列及具体的拒绝策略
* arraylist和linkedlist的区别
* 集合框架有哪些线程安全的集合类
* 集合的源码
* 集合、hashmap的底层原理、concurrenthash与hashtable区别
* hashmap的扩充原理 hashmap扩容时候，put一个元素进来，hashmap是怎么处理的
* concurrenthashmap实现的原理，为什么是线程安全的
* jdk1.8之后还用concurrenthashmap吗

##### List、Set、Map

##### HashTable
实现了多线程安全，在几乎所有的方法上都加上了synchronized锁，而加锁的结果就是HashTable操作的效率十分低下。

##### HashSet
底层通过HashMap实现。因此也是非线程安全的。

##### HashMap
非线程安全。仅适用于单线程中。
###### HashMap处理哈希冲突的方式
链地址法
###### 怎么样会触发HashMap的扩容？
size达到阙值（threshold）。threshold = capacity（数组最大长度） * loadfactor（扩容因子）
###### 插入、查找时，如何为Key定位
1. 先取hashcode
2. 根据hashcode获得数组下标
3. 根据数组下标获得Entry、遍历Entry链表，若hashcode一致、key.equal为true或key相等
###### 插入时，是插入在链表的头部还是尾部
1.8之前：头部。又名头插法。（个人想法：若插入到尾部，还需要遍历链表到尾部，增加了耗时）
1.8及1.8之后：尾部。
###### HashMap是怎么遍历的，遍历时可以插入和删除元素吗？
实现：HashMap.AbstractMapIterator
modCount：HashMap用来记录对数据进行插入、删除的次数；
expectedModCount：AbstractMapIterator用来记录对数据进行插入、删除的次数；

若在遍历时执行插入、删除操作，发现modCount和expectedModCount不一样，会抛出异常。

* 调用hashmap.remove()或hashmap.put()时，会修改modCount，但不会修改expectedModCount
* 调用Iterator.remove()时，会同时修改modCount和expectedModCount

因此遍历时，不可以插入，可以删除（但要用iterator.remove()）。

###### 什么是扰动函数？
HashMap为了减少哈希冲突而设计的函数。
在1.8版本的HashMap中，是这样取哈希值的：
```java
static final int hash(Object key) {
int h;
return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

即HashMap的hash方法，就是扰动函数的实现。
采用了 hashcode 的高 16 位和低 16 位异或的方法，去降低 hash 碰撞。
（参考：https://blog.csdn.net/weixin_42373997/article/details/112085344）

###### 不同JAVA版本HashMap实现的区别
||1.6的HashMap|1.7的HashMap|1.8的HashMap|
|---|---|---|---|
|如何取hashcode|key.hashcode()|sun.misc.Hashing.stringHash32((String) key)|(key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16) |
|如何扩容|超过阙值，则创建一个容量为原数组2倍的新数组，然后重新计算哈希值存进去|与1.6一样|与1.6一样|
|如何取数组下标|hashcode & this.elementData.length - 1|与1.6一样||
|如何实现链表|Map.Entry|Map.Entry|HashMap.Node、HashMap.TreeNode（树化后）|
|在链表哪里插入新的元素|链表头插入|链表头插入|链表尾插入|
|迭代器|HashMap.AbstractMapIterator|HashMap.AbstractMapIterator|Spliterator（并行迭代器）|

##### LinkedHashMap
事实上LinkedHashMap是HashMap的直接子类，二者唯一的区别是LinkedHashMap在HashMap的基础上，采用双向链表(doubly-linked list)的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同。
```java
Entry<K,V>[] table; //存储HashMap的地方
Entry<K,V> header;//按插入顺序维护的一个LinkedList
```

##### TreeMap
###### Treemap是有序的吗？
是的。默认排序规则：按照key的字典顺序来排序（升序）。
也可以自定义排序规则（Comparator接口）
###### 是线程安全类吗？
不是线程安全的。若想线程安全，可通过如下方法：
```java
SortedMap m = Collections.synchronizedSortedMap(new TreeMap(...));
```
###### 红黑树的原理？
逻辑上是一棵“2-3-4树”。下图可知，2-3-4树是一棵“多叉树”，一个节点里可包含1~3个值。
包含一个值的叫2-节点（2个子树），对应红黑树的黑节点；
包含两个值的叫3-节点（3个子树），对应红黑树的一个黑根、一个红子；
包含三个值的叫4-节点（4个子树），对应红黑树的一个黑根、两个红子；
![331b6c466d9c52098902ba9ca263a71c.png](en-resource://database/963:1)

###### 为什么有二叉搜索树（BST），还要有平衡二叉树（AVL树）？为什么又要有红黑树？为什么又会有B-树？为什么又会有B+树？
* 二叉搜索树（BST）：
  查找最坏情况为O(N)，即树成链表状的时候
* 平衡二叉树（AVL）：
  在二叉搜索树的基础上，加上了“自平衡”的逻辑（左右子树树高超过1则对树进行旋转），避免树成为链表的形状；
  查找的平衡和最坏情况均为O(logN)；
* 红黑树（RBT）：
  红黑树也是一棵二叉搜索树，查找的时间复杂度最坏情况是O(2logN)，比平衡二叉树稍差，但因为插入、删除操作更简单，旋转操作更少，所以总体性能优于平衡二叉树
* B-树：
  B-树是一棵多路搜索树，通过增加阶数（增加子树数量），使树变得更“矮”，查询效率就可以比红黑树更高。
* B+树：
   B+树也是一棵多路搜索树，只不过B+树的数据只存储在叶子节点，且叶子节点之间增了指针相连，方便遍历和范围搜索。
   现在大多数数据库的数据以及索引都默认通过B+树来存储。可参考Mysql的数据及索引存储结构。



##### 队列、栈
###### Stack类（官方不建议使用）
peek()
pop()
push(E)
###### Queue接口

offer(e) 
remove()  
poll() 
element()
peek()

###### Duque接口（双向队列。既可当栈用，又可当队列用）
继承Queue接口

***API***
* 当队列（Queue）用：
offerLast(e)（入队，也可以用offer(e)、add()、addLast(e)）
E pollFirst() （出队，也可以用poll()、remove()、removeFirst()）
E peekFirst()（获取头节点（first），也可以用peek()、getFirst()、element()）

* 当栈（Stack）用：
addFirst(e)（进栈）
removeFirst()（出栈）
peekFirst()（获取栈顶元素）

总结：
1.add、remove、get方法（Collection接口的方法）若失败，均会抛出异常；
2.offer、poll、peek方法（Queue接口的方法）若失败，则会返回null或false；
3.后缀为First、Last的均为Deque接口的方法（因为是双端队列）；

***实现：***
***非线程安全：LinkedList、ArrayDeque***
***LinkedList***
解决方法：Collections.synchronizedList()
底层是链表：Node(first)-> Node-> Node-> Node-> Node(last)

***ArrayDeque***
变为线程安全：Collections.synchronizedList()
底层是数组+head指针+tail指针：
![d4f9e92ce7d22f49ae7f98d5c3062057.png](en-resource://database/957:1)
如何扩容：
申请一个更大的数组(原数组的两倍)，然后将原数组复制过去

***线程安全：ConcurrentLinkedQueue（继承Queue接口）、BlockingQueue接口***

***ConcurrentLinkedQueue类***
通过CAS操作操作（UNSAFE）实现资源同步（无锁）；
队列中无数据时出队、或者队列满了时入队，都会操作失败，但不会阻塞线程，而是返回null或false；想阻塞的话可使用BlockingQueue的实现。
特点：HOPS(延迟更新的策略)的设计

***BlockingQueue接口及其实现***
***BlockingQueue在入队出队失败后，应对方式比ConcurrentLinkedQueue灵活。***
与ConcurrentLinkedQueue类一样，队列中无数据时出队、或者队列满了时入队，都会操作失败；
但BlockingQueue为操作失败之后提供了多种应对方法：

||抛异常 |特定值 |阻塞 |超时 |
|---|---|---|---|---|
|入队 |add(o) |offer(o) |put(o) |offer(o, timeout, timeunit) |
|出队| remove(o)| poll(o) |take(o) |poll(timeout, timeunit) |
|检查| element(o)| peek(o)||

此外还有双端队列BlockingDeque（继承了BlockingQueue）

***BlockingQueue的实现***
ArrayBlockingQueue 有界数组阻塞队列

DelayQueue 无界延迟队列

LinkedBlockingQueue 有界链阻塞队列

PriorityBlockingQueue 无界优先级阻塞队列（插入的元素需要继承Comparable接口）

SynchronousQueue 同步队列（内部同时只能够容纳单个元素）


##### 线程池ThreadPoolExecutor
问题：
* 创建线程的方式有哪些
* 实现runnable和callable的区别
* sleep和wait方法的区别
* 为什么不推荐用Executors里提供的线程池初始化的方法？
主要原因都是最大线程数量设置为Integer.MAX_VALUE,或者使用无界队列。

newCachedThreadPool()：
可变长线程池。最大线程数为Integer.MAX_VALUE，并发过大时会导致OOM；

newFixedThreadPool()：
定长线程池。用的是LinkedBlockingQueue（无界队列），该队类长度为Integer.MAX_VALUE，过多任务进队时会导致OOM；

newScheduledThreadPool()：
支持定时任务的线程池。最大线程数为Integer.MAX_VALUE，并发过大时会导致OOM；

* 线程池的核心参数与流程，任务队列及具体的拒绝策略
```java
//线程池实现类
public class ThreadPoolExecutor extends AbstractExecutorService{

private final HashSet<ThreadPoolExecutor.Worker> workers;//线程集合
private final BlockingQueue<Runnable> workQueue;//等待被执行的任务队列
private final ReentrantLock mainLock;
private final Condition termination;
//RejectedExecutionHandler默认实现是ThreadPoolExecutor.AbortPolicy
private volatile RejectedExecutionHandler handler;//入任务队列失败的处理策略
private volatile ThreadFactory threadFactory;//创建线程的工具

}
```

* 生成线程池
```java

//【生成一个可变长线程池】
ExecutorService service = Executors.newCachedThreadPool()
//【生成一个定长线程池】
ExecutorService service = Executors.newFixedThreadPool(int arg)
//【生成一个定长线程池（支持定时、周期性任务）】
ScheduledExecutorService service = Executors.newScheduledThreadPool()
//【生成一个单线程化的线程池】
ExecutorService service = Executors.newSingleThreadExecutor()
/**
 【自定义线程池】
 参数：
 1、corePoolSize：核心线程数
        * 核心线程会一直存活，及时没有任务需要执行
        * 当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理
        * 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭
2、maxPoolSize：最大线程数
        * 当线程数>=corePoolSize、当前没有空闲线程、且任务队列已满时，线程池会创建新线程来处理任务
        * 当线程数=maxPoolSize、当前没有空闲线程、且任务队列已满时，线程池会拒绝处理任务而抛出异常
3、 keepAliveTime：线程空闲时间
        * 当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize
        * 如果allowCoreThreadTimeout=true，则会直到线程数量=0
4.  线程空闲时间单位
5.  workQueue 工作队列，用于存储任务在任务被执行之前
6.  threadFactory 线程创建工厂，用于创建线程
7.  RejectedExecutionHandler 当workQueue工作队列达到容量上限时，对任务进行的拒绝策略。
**/
public ThreadPoolExecutor(int arg0, int arg1, long arg2, TimeUnit arg4,
BlockingQueue<Runnable> arg5, ThreadFactory arg6,
RejectedExecutionHandler arg7)

/**
ExecutorService是接口，ThreadPoolExecutor是该接口的实现
Executors.newCachedThreadPool() 等同于以下写法
**/
ExecutorService service =new ThreadPoolExecutor(0, Integer.MAX_VALUE,  
                                  60L, TimeUnit.SECONDS,  
                                  new SynchronousQueue<Runnable>())
 
```
* 执行任务
```java
//有回参
Future future = service.submit(Callable);
//无回参
service.execute(Runnable);
```
* 关闭线程池
```java
service.shutdown();
```
* 任务队列满后的拒绝策略
    * AbortPolicy（直接抛出异常，任务没有被执行。默认策略）
    * DiscardOldestPolicy（放弃队列中最旧的任务，然后将新任务入队）
    * DiscardPolicy（直接放弃任务，什么都不做）
    * CallerRunsPolicy（会调用当前线程池的所在的线程去执行被拒绝的任务，缺点是会阻塞主线程）

#### JAVA事务
##### 1.事务的概念
事务（Transaction）：一般是指要做的或所做的事情。在计算机术语中是指访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。

##### 2.事务四个属性（ACID）
1. atomicity 原子性
原子性：操作这些指令时，要么全部执行成功，要么全部不执行。只要其中一个指令执行失败，所有的指令都执行失败，数据进行回滚，回到执行指令前的数据状态。
2. consistency 一致性
 一致性：事务的执行使数据从一个状态转换为另一个状态，但是对于整个数据的完整性保持稳定。
3. isolation 隔离性
隔离性：在该事务执行的过程中，无论发生的任何数据的改变都应该只存在于该事务之中，对外界不存在任何影响。只有在事务确定正确提交之后，才会显示该事务对数据的改变。其他事务才能获取到这些改变后的数据。
4. durability 持久性
持久性：当事务正确完成后，它对于数据的改变是永久性的。

##### 3.并发事务导致的问题
在许多事务处理同一个数据时，如果没有采取有效的隔离机制，那么并发处理数据时，会带来一些的问题。

1. 脏读(Dirty Read)
当一个事务读取另一个事务尚未提交的修改时，产生脏读。
同一事务内不是脏读。 一个事务开始读取了某行数据，但是另外一个事务已经更新了此数据但没有能够及时提交。这是相当危险的，因为很可能所有的操作都被回滚，也就是说读取出的数据其实是错误的。

2. 不可重复读(Nonrepeatable Read)
一个事务对同一行数据重复读取两次，但是却得到了不同的结果。同一查询在同一事务中多次进行，由于其他提交事务所做的修改或删除，每次返回不同的结果集，此时发生不可重复读。

3. 幻读(Phantom Reads)
事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据（这里并不要求两次查询的SQL语句相同）。这是因为在两次查询过程中有另外一个事务插入数据造成的。
当对某行执行插入或删除操作，而该行属于某个事务正在读取的行的范围时，会发生幻像读问题。

4. 丢失修改(Lost Update)
第一类：当两个事务更新相同的数据源，如果第一个事务被提交，第二个却被撤销，那么连同第一个事务做的更新也被撤销。
第二类：有两个并发事务同时读取同一行数据，然后其中一个对它进行修改提交，而另一个也进行了修改提交。这就会造成第一次写操作失效。

##### 4.事务隔离级别
为了兼顾并发效率和异常控制，在标准SQL规范中，定义了4个事务隔离级别.

1. 读未提交(Read Uncommitted)
直译就是"读未提交"，意思就是即使一个更新语句没有提交，但是别的事务可以读到这个改变。
Read Uncommitted允许脏读。

2. 读已提交(Read Committed)
直译就是"读提交"，意思就是语句提交以后，即执行了 Commit 以后别的事务就能读到这个改变，只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别。
【原理】读已提交就是改变了释放锁的时机，让事务完成提交后再去释放锁。这样就解决了脏读问题。
Read Commited 不允许脏读，但会出现非重复读。


3. 可重复读(Repeatable Read)：
直译就是"可以重复读"，这是说在同一个事务里面先后执行同一个查询语句的时候，得到的结果是一样的。
【原理】MVCC（行级锁的升级版，略）
Repeatable Read 不允许脏读，不允许非重复读，但是会出现幻象读。

4. 串行读(Serializable)
直译就是"序列化"，意思是说这个事务执行的时候不允许别的事务并发执行。完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。
Serializable 不允许不一致现象的出现。

通过不同的隔离级别，可以防止一些并发事务问题，同时级别越高则相应性能越低，这个设置需要根据实际场景进行设置。

常见商用数据库的默认隔离级别：
* MYSQL 可重复读（RR）
* ORACLE 读已提交（RC）
* SQL SERVER 读已提交（RC）

###### 不同隔离级别会遇到的问题
（✔为没有解决，✖为可解决）
| 隔离级别| 脏读| 不可重复读|幻读|
|---|---|---|---|
|读未提交|✔|✔|✔|
|读已提交|✖|✔|✔|
|可重复读|✖|✖|✔|
|串行读|✖|✖|✖|

###### Oracle、Sql Server 既然默认的隔离级别为“读已提交”，那么它们是怎么解决幻读和不可重复读的？
解决不可重复读：MVCC机制；
解决幻读：MVCC机制+Next-key Lock锁；



#### JAVA多线程

##### Java新建线程有哪几种方式？
>* Thread
> ```java
> Thread t = new Thread();
> t.run();
> ```
> 
> * Runnable接口
> ```java
>  public static void main(String[] args) {
>  Thread thread = new Thread(new MyRunnable());
>  thread.start();
> }
>public class MyRunnable implements >Runnable {
>    @Override
>    public void run() {
>        // ...
>    }
>}
> 
> ```
> * Callable接口
> ```java
> public static void main(String[] args) {
>  FutureTask task = new FutureTask(new MyCallable());
>  Thread thread = new Thread(task);
>  thread.join(); //在thread.start之后，等待线程执行完之后，再继续往下执行
>  System.out.println("join!");
>  thread.start();
>  System.out.println("after start!");
>  System.out.println("result="+task.get());
>  //最后输出顺序是：join! -> after start! -> generate 123! -> result=123
> }
> public class MyCallable implements 
>  Callable<Integer> {
>     public Integer call() {
>     System.out.println("generate 123!");
>     Thread.currentThread().sleep(5000);
>     return 123;
>     }
> }
> ```



##### 通过线程池创建线程：Executor框架
>    (1). 获取线程池
>     * 可变长线程池
>```java
>//生成一个可变长线程池
>ExecutorService pool = Executors.newCachedThreadPool()
>```
> * 定长线程池
> ```java
> //生成一个定长线程池
> ExecutorService pool = Executors.newFixedThreadPool()
>```
> * 轮询线程池
> ```java
> //生成一个定长线程池（支持定时、周期性任务）
> ExecutorService pool = Executors.newScheduledThreadPool()
>```
> (2).获取线程执行任务
> ```java
> //
> Future future = pool.execute(new Runnable(){});
> ```
> 

##### volatile Integer 和AtomicInteger的区别？
>    AtomicInteger： 本身即可满足线程安全的三个条件：原子性、可见性、有序性；
>
>    volatile Integer：只能满足可见性和有序性，所以遇到 i++这种操作，还是需要先加锁再操作。

##### JAVA里线程（Thread）的生命周期？

新建（new）
就绪（runnable）
运行 （running）
阻塞（blocking）
睡眠（time waiting，等待通知或等待一段时间）
等待（waiting，等待通知）
结束（dead）
##### Thread里的函数解析
```java
/**在调用interrupt时，若thread正被阻塞（等待IO、或在synchronized代码块前等待锁），则可让thread停止阻塞，抛出异常。
若thread没有被阻塞，则不会抛出异常。
若想在运行时也可以中断，可在thread的run()中加入isInterruped()的判断。
**/
thread.interrupt();
/**
开始线程
**/
thread.start();
/**
线程休眠（不会交出占用的锁）
**/
thread.sleep(long millis);
/**
线程是否活跃
**/
thread.isAlive();
/**
thread线程阻塞当前线程，当thread执行完后，当前线程才继续执行
**/
thread.join();
```
##### Thread如何从一个生命周期进入另一个生命周期？

新建（new）
```java
public static void main(String[] args){
//此时进入新建态
Thread thread = new MyThread();
}
```
新建（new） --> 就绪（runnable）
就绪（runnable） --> 运行 （running）
```java
thread.start(); 
//调用start()后获取到CPU时间片，start()再调用run()，此时才算正式进入运行态
```

运行 （running） --> 阻塞（blocking）
```java
//1.遇到同步代码块时，thread便会被阻塞
public class MyThread {
    public void run(){
        synchronize(this){
           // ...
        }
        
    
    }
}
```

运行 （running） --> 睡眠（time waiting）
运行 （running） --> 等待（waiting）
```java
//第一种：lock.wait()
public class MyThread {
    Object lock = new Object();
    public void run(){
        //为什么wait()、notify()、notifyAll()需要在synchronized里执行？
        //语法上：不写在synchronized内，运行时会抛出异常
        //原理上：当前线程必须拥有对象的monitor（内置锁），调用对象的wait()、notify()、notifyAll()方法时才能有锁可以释放
        synchronized( lock ){
            try {
                    // ...
                    //释放lock对象，线程等待1s，1s后重新竞争lock对象，竞争到lock对象后继续往下走
                    lock.wait(1000);
                } catch (InterruptedException e) {
                      e.printStackTrace();
                }

        }
    }
}
```
```java
//第二种：thread.join() (实质是调用了thread.wait())
public static void main(String[] args){
//此时进入新建态
Thread thread = new MyThread();
//等待thread执行完后，主线程再执行（等于异步变同步）
thread.join(1000);
}
```
```java
//第三种：
public class MyThread {
public void run(){
    LockSupport.pack(this);//当前线程等待，直至其他线程调用LockSupport.unpack(this)
}
//等待thread执行完后，主线程再执行（等于异步变同步）
thread.join();
}
```
睡眠（time waiting） --> 就绪（runnable）
```sql
/**
1. lock.nofity() or lock.notifyAll() ; //对应第一种方式
2. LockSupport.unpack(this) //对应第三种方式
**/
```


##### 有哪些常见的锁？

|类型|可重入|悲观锁|可中断锁|公平锁|互斥锁|独占锁|
|---|---|---|---|---|---|---|
|synchronized|√|√|×|×|√|√|
|ReentrantLock|√|√|√|都可，默认非公平|√|√|
|ReentrantReadWriteLock|√|√|×|都可，默认非公平|×(读写锁)|读锁是共享锁，写锁是独占锁|
|Unsafe.compareAndSwap()|-|×|-|-|×(自旋锁)|-|
|Semaphore|-|√|-|都可，默认非公平|-|×|
|CountDownLatch|-|√|-|都可，默认非公平|-|×|


* 可重入？
当某个线程已调用该锁并持有，在被锁的代码段里面仍可以继续调用锁，则该锁是可重入锁；
换言之，当某线程调用锁，进入代码，然后再次调用锁，若此时不能继续进入该代码，则是不可重入锁。

* 悲观or乐观？
当读、写都要调用锁，悲观锁；
读写都不锁，只有在写时检测是否有冲突，有冲突则返回错误给用户，乐观锁；
* 可中断？
当线程A想要的锁一直被另一线程B占据，若线程A需要一直阻塞等待锁，即是不可中断锁；
反之，若线程A可等待一段时间后返回失败，则是可中断锁。
* 公平？
若线程A最先请求锁，最终亦是线程A最先获得锁，那么该锁便是公平锁；
反之，若线程A不一定最先获得锁，便是不公平锁。
* 互斥or读写？
当读、写都要调用锁，互斥锁；
当读时，大家可以共用该锁；写时，只有一人可以占用该锁，读写锁；
* 互斥or自旋？
互斥锁(mutex)：竞争锁失败时，线程会挂起，进入阻塞态；等待解锁后，重新竞争CPU时间片
自旋锁(spin)：竞争锁失败时，线程不会挂起，而是一直轮询锁是否能用一段时间；一段时间内还获取不到，才挂起线程，进入阻塞态。
* 独占or共享？
独占锁（写锁）：一个资源只能被线程上一次独占锁
共享锁（读锁）：一个资源能被多个线程上多次共享锁



##### 乐观锁的优点



##### 关于Java乐观锁、自旋锁：Unsafe类
像原子类（AtomicInteger等类）、AbstractQueuedSynchronizer（AQS，ReentrantLock、CountDownLatch的底层实现），都是通过Unsafe类的CAS操作（乐观锁操作）实现。

> 既然底层是通过乐观锁实现，那为什么说ReentrantLock是悲观锁？
> 


如何实例化Unsafe对象
> 由Unsafe类的源码可知，只有JDK自带的类（即BootstrapClassLoader加载的类），才能使用getUnsafe()获取unsafe类
> 若开发者想自己获取unsafe类，只能通过反射方式获取（如下示例）：
```java
    public static void main(String[] args)
        throws NoSuchFieldException, IllegalAccessException {
        Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
        theUnsafe.setAccessible(true);
        Unsafe unsafe = (Unsafe) theUnsafe.get(null);
        System.out.println(unsafe);
    }
```

Unsafe类核心代码
```java
public final class Unsafe {
    private static final Unsafe theUnsafe;

    private Unsafe() {
    }

    @CallerSensitive
    public static Unsafe getUnsafe() {
        Class var0 = Reflection.getCallerClass();
        if (!VM.isSystemDomainLoader(var0.getClassLoader())) {
            throw new SecurityException("Unsafe");
        } else {
            return theUnsafe;
        }
    }

    //...
}
    
```


##### CAS操作
Unsafe提供了3个CAS函数，来实现乐观锁。
所谓CAS函数，即compareAndSwapObject()、compareAndSwapInt()、compareAndSwapLong()。
它包含3个入参：要修改变量的内存位置、预期原值、要修改为的值
比如，有一个student对象，要使用自旋锁的方式，修改它的name属性。
CAS操作，若成功则返回true，失败则返回false
```java

    public void test(Student student,String newName){
        //1.获取unsafe，略
        try {
            //2.使用Unsafe类，实现上自旋锁修改name属性
            long valueOffset = unsafe.objectFieldOffset(Student.class.getDeclaredField("name"));
            String oldName = unsafe.getAndSetObject(student, valueOffset, newName);
            //getAndSetObject()是自旋锁实现，实际也是调用compareAndSwapObject()方法
        } catch (Exception var1) {
            throw new Error(var1);
        }
    }
```




##### JUC简介
![e3197fc4e1ad1393da309bdad29de4d8.png](en-resource://database/959:1)

###### AQS
* 什么是AQS？

抽象的队列式的同步器。

ReentrantLock/Semaphore/CountDownLatch的底层实现。


##### Lock接口
为什么有synchronized，还需要再提出Lock接口？

因为synchronized无法解决线程死锁的问题。
产生线程死锁需要满足以下条件：
1. 互斥条件（一段时间内某一资源仅为一线程所持有）
2. 请求和保持条件（当线程请求资源而阻塞时，不会释放自己拥有的资源）
3. 不可抢夺条件（线程为使用完的资源不能被剥夺，只能在使用完时释放）
2. 环路等待条件（在发生死锁时，必然存在一个进程--资源的环形链，如下）
线程1占有锁1，等待锁2；
线程2占有锁2，等待锁3；
...
线程N占有锁N，等待锁1。

解决线程死锁，一般方法是破坏条件3，即“不可抢夺条件”。

想破坏“不可抢夺条件”，有如下方法：
1. 线程能响应中断（对应lock.lockInterruptibly()）
2. 线程可以非阻塞地获取锁（对应lock.tryLock()，获取不到立即返回false）
3. 支持超时（对应lock.tryLock(long time)）

从上面可看到，JDK1.5后发布的Lock接口有对应的API支持。

###### ReentrantLock
三个内部类：Sync、NonfairSync、FairSync。NonfairSync、FairSync集成Sync，而且都是AQS的实现类。

FairSync类：采用公平策略获取锁
NonfairSync：采用非公平策略获取锁（默认）


#####  JUC Tools
###### Semaphore
Semaphore称为计数信号量，它允许n个任务同时访问某个资源，可以将信号量看做是在向外分发使用资源的许可证，只有成功获取许可证，才能使用资源。
```java
//假设只能允许10个用户同时在线
Semaphore semaphore=new Semaphore(10);
//用户登录，占用1个信号量
boolean isLogin= semaphore.tryAcquire();
//查看剩余多少用户可以登录
int restCount=semaphore.availablePermits();

```
###### CountDownLatch
CountDownLatch典型的用法是将一个程序分为n个互相独立的可解决任务，并创建值为n的CountDownLatch。当每一个任务完成时，都会在这个锁存器上调用countDown，等待问题被解决的任务调用这个锁存器的await，将他们自己拦住，直至锁存器计数结束。
```java
//定义了一个计数器，当前计数为1
CountDownLatch begin = new CountDownLatch(1);
//阻塞当前线程，等待计数器到0
begin.await();
//（在另外的线程）任务完成，计数-1
begin.countDown();
```
###### LockSupport



##### JUC Collections
###### HashTable
HashTable也是线程安全类，但它在执行put等操作时，是直接用synchronized关键字修饰的，即put时它会对整个对象加锁，锁住整个Hash表，这样会影响效率。
因此一般使用ConcurrentHashMap。

###### ConcurrentHashMap

**JDK1.7版本（Segment桶模式，也称为分段锁机制）**
ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承 ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。

Segment 内部是由 数组+链表 组成的。

segment 数组不能扩容，扩容的是Segment内部的数组。

默认有16个Segment。（concurrencyLevel=16）

**简单叙述ConcurrentHashMap 1.7中put操作的原理**
concurrentHashMap.put: 先取key的hashcode，根据hashcode求出所属Segment的下标（与15进行与操作）；

求得所属Segment后，调用Segment的put方法；

segment.put: 先获取独占锁，再根据key的hashcode获得node的下标；

若node没有value，直接赋值；若node有value，则比较hashcode是否一致，一致则直接覆盖，不一致则比较下个node



**JDK1.8版本（与HashMap类似的数组+链表+红黑树的方式实现）**

1.8摒弃了分段锁机制，使用与HashMap类似的数组+链表+红黑树的结构。
线程安全则是通过CAS和synchronized来实现。

**简单叙述ConcurrentHashMap 1.8中get操作的原理**
get操作全程不加锁，只通过volatile关键字修饰Node节点，保证数据的可见性、有序性。但不保证原子性。




**简单叙述ConcurrentHashMap 1.8中put操作的原理**
concurrentHashMap.put: 同样，先取key的hashcode，根据hashcode求出所属Node的下标（tabAt(tab, i = (n - 1) & hash)）；

若下标处node=null，则直接插入新值即可。插入时会进行一次cas操作，若操作失败则证明有并发操作，重新插入一次（casTabAt(...)）；

>CAS操作：即调用sun.misc.Unsafe的compareAndSwapObject()方法，传入了node数组、下标、旧值和新值。
>原理是先将旧值与node数组下标对应的值比较，若相等，则直接插入新值，返回true（表示操作成功）；
>若不相等，则表示数组已经被修改过，直接返回false（表示插入失败）。

若下标处node不为空，则用synchronized将node锁住，再遍历链表去存储值。



#### JVM

JVM内存模型：

* 进程控制块
  * 程序计数器
* 本地接口
* 运行时数据区
  * 堆------------------------------存储对象、字符串常量（1.7之后）
    * 新生代------------------------对象
    * 老年代------------------------对象
    * 永久代（1.7之前作为方法区）-----静态变量、常量、类信息
  * 方法区--------------------------存储类信息、静态变量和常量值
  * 线程空间
    * 栈----------------------------存储基本类型变量和对象引用
    * 线程控制块
    * 虚拟缓存


##### JVM都存储什么数据？存储在哪里？
1.7之前：
基本数据类型变量(int,float,double等) ——  栈帧（线程空间）
对象引用 —— 栈帧（线程空间）
静态变量 —— 堆->  永久代（被称为方法区）
常量值 —— 堆->  永久代（被称为方法区）
类信息(.class) —— 堆->  永久代（被称为方法区）
字符串常量值 ——  字符串常量池
对象 —— 堆 -> 新生代、老年代


1.7之后：
基本数据类型变量(int,float,double等) ——  栈帧（线程空间）
对象引用 —— 栈帧（线程空间）
静态变量 —— 堆
常量值 —— 元数据metaspace（也被称为方法区）
类信息(.class) —— 元数据metaspace（也被称为方法区）
字符串常量值 —— 堆->  字符串常量池
对象 —— 堆 -> 新生代、老年代

>简单来讲：
>栈帧：存储基本类型变量和对象引用；
>方法区：存储类信息和常量值；1.7之前在堆里，1.7后独立出来，命名为元数据metaspace；
>堆：存储对象，分为新生代、老年代；永久代只有1.7之前有，1.7后独立出来被称为元数据metaspace；
>字符串常量池：存储字符串常量，1.7之前在堆外、1.7之后移到了堆内。


##### 说说下面变量的加载顺序是怎样的
先看是否静态：静态优先级更高；
若都是静态，则无论是代码块还是成员变量，谁先声明谁先执行。

优先级
1、静态成员变量 / 静态代码块: 他们的优先级相同,谁先声明谁先执行
2、普通成员变量 / 构造代码块: 他们的优先级相同,谁先声明谁先执行
3、构造代码块优先于构造方法执行,每创建一个对象就调用一次构造代码块和构造方法
4、普通方法和静态方法没有任何区别,谁先调用就谁先执行
```java
public class Test{
  
  String a=1;//变量
  static String b=2;//静态变量
  static final String c=3;//静态常量
  String d;
  String e;
  String f;

  //静态代码块
  static{
    d = 4;
  }
  //构造代码块
  {
    e = 5;
  }
  //构造方法
  public Test(){
    f = 6;
  }
  
  public static void main(String[] args){
      g= 7;
  }

}
```

##### JVM如何管理内存？
JVM会自动回收对象。需要被回收的对象被称为“垃圾”。
对象回收又被称为“GC”；
根据回收堆里哪部分的对象，GC又分为：MinorGC（新生代）、Major GC（老年代）、Full GC（新+老）；

##### 怎么样判断对象是否可回收？
JVM通过“可达性分析算法”，来判断对象是否需要被回收。
即维护了多个树表，根节点名为GC Root，若通过遍历GC Root的子树能找到某个对象，则认为该对象是“存活的”，无需被回收。

以下这些都可以作为GC Root：
* 存活的线程（Thread）
* Java虚拟机栈中引用的对象
* 方法区中静态变量引用的对象
* 方法区中常量引用的对象
* 本地方法栈中JNI引用的对象

##### 什么是MinorGC？Major GC？Full GC？
* MinorGC：清理新生代的内存，并将部分存活的对象晋升到老年代
>具体方法是：将Eden区清空，将Eden区和Suvivor区中存活的对象移动到另一个Suvivor区中。将对象的年龄+1。

* MajorGC：清理老年代的内存

* FullGC：清理新生代+老年代+方法区的内存

##### 怎么触发新生代晋升到老年代？
1. Eden区满，触发了MinorGC
2. 大对象，直接进入老年代（XX:PretenureSizeThreshold）
3. Survivor中年龄超过一定临界值的（XX:+MaxTenuringThreshold）
4. Survivor区中对象占用空间的大小之和超过50%
5. MinorGC后对象过多，无法完全放入Survivor区，就会向老年代借用内存存放对象，以完成MinorGC

##### 怎么触发GC?

Minor GC触发条件：
* Eden区域满了
* 新生对象需要分配到新生代的Eden，当Eden区的内存不够时需要进行MinorGC

Major GC触发条件：
* Survivor区中对象占用空间的大小之和超过50%

Full GC触发条件：
* 上面Minor GC时介绍中Survivor空间不足时，判断是否允许担保失败，如果不允许则进行Full GC。如果允许，并且每次晋升到老年代的对象平均大小>老年代最大可用连续内存空间，也会进行Full GC。

* MinorGC后存活的对象超过了老年代剩余空间

* 方法区内存不足时

* System.gc()，可用通过-XX:+ DisableExplicitGC来禁止调用System.gc

* CMS GC异常，CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，会触发Full GC

##### JVM如何实现GC？有哪些GC算法？

默认垃圾回收器：
JDK1.3之前 
* 新生代：Serial（串行的Copying算法） 
* 老年代： Serial Old（串行的Mark-Compact算法）

JDK1.8之前 
* 新生代：Parallel Scavenge（并行的Copying算法） 
* 老年代：Serial Old（串行的Mark-Compact算法）、Parallel Old（1.8，并行的Mark-Compact算法）

JDK1.9 
新生代、老年代均用：G1

JDK1.11之后
ZGC

***垃圾收集器简述***

**Serial垃圾回收器（既有新生代的：Serial、也有老年代的Serial Old）**
只使用一个GC线程进行回收（串行），会暂停所有的用户线程，不适合服务器环境。

**Parallel垃圾回收器（既有新生代的：ParNew、Parallel、也有老年代的：Parallel Old）**
多个GC线程进行垃圾回收（并行），也会暂停所有用户线程，适用与和前台交互不强的场景，如科学计算/大数据处理等若交互场景。

***CMS垃圾回收器：老年代回收器，推荐配合ParNew使用***
基于Mark-Sweep（“标记-清除”）算法
若干次GC后需要进行一次碎片整理。
优点：大部分时间能与用户线程并行运行。
缺点：有内存碎片，若需要为较大的对象分配内存，容易又会触发GC

过程：
初始标记(CMS-initial-mark) ,会导致stw;
并发标记(CMS-concurrent-mark)，与用户线程同时运行；
预清理（CMS-concurrent-preclean），与用户线程同时运行；
可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行；
重新标记(CMS-remark) ，会导致stw；
并发清除(CMS-concurrent-sweep)，与用户线程同时运行；
并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行。

***G1垃圾回收器***
基于Mark-Compact（“标记-整理”）算法
优点：回收得到的内存空间是连续的。

过程：
Eden区满，触发Minor GC：回收新生代；
Full GC：回收新生代、老年代、永久代（JDK1.8后为metaspace）

###### 垃圾回收算法简述
***Copying（标记复制）算法：新生代的算法***
将内存分为大小相等的两份（即现在的Eden区和Survivor区）
1.Eden区满后，触发一次GC：标记Eden区的存活对象，将存活对象移至其中一个Survivor区（Survivor0）
2.清空Eden区
3.Eden区又满，触发一次GC：标记Eden区及Survivor区的存活对象，将存活对象移至另一个Survivor区（Survivor1）
4.清空Eden区和Survivor0区
5.若存活对象经历GC的次数达到一个阙值（-XX:MaxTenuringThreshold），则会被移进老年代

优点：无需清除和整理、效率较高；不会产生内存碎片。适合会有大量失活的新生代
缺点：需要两倍的内存空间

***Mark-Sweep（“标记-清除”）算法：老年代的算法***
1. 标记需要清除的对象
2. 清除

优点：快速简单
缺点：有内存碎片，若需要为较大的对象分配内存，容易又会触发GC

***Mark-Compact（“标记-整理”）算法：老年代的算法***
1. 标记需要清除的对象
2. 让存活对象移至一端
3. 清除

##### 与垃圾回收相关的系统参数
XX:+MaxTenuringThreshold =15 晋升到老年代需要的年龄

XX:TargetSurvivorRatio =50% Survivor空间占用超过50%，会将年龄较大的晋升到老年代

XX:NewRatio=1:2 新生代与老年代的比例（默认1:2）

XX:SurvivorRatio=8:1:1 Eden区与Survivor区的比例（默认8:1:1）

XX:PretenureSizeThreshold= 对象大于此参数的值，则绕过新生代，直接分配到老年代（只对Serial及ParNew有效）

Xms —— 堆的初始大小

Xmx —— 最大堆内存

XX:NewSize / XX:MaxNewSize — 设置新生代大小/新生代最大大小

XX：MaxPermSize —— 最大方法区内存（1.8之后该参数无效，因为metaspace无限大）

###### 开启垃圾回收器类的参数
XX:+UseSerialGC （新生代用：Serial 老年代用：Serial Old）
XX:+UseParNewGC（新生代用：ParNew 老年代默认用：Serial Old）
XX:+UseParallelGC（新生代用：Parallel Scavenge 老年代默认用：Serial Old(1.8前)、Parallel Old(1.8后)）
XX:+UseParallelOldGC（老年代用：Parallel Old，新生代：自动激活-XX:+UseParallelGC使用）
XX:+UseConcMarkSweepGC （老年代用：CMS，新生代：自动激活-XX:+UseParNewGC使用）
XX:+UseG1GC （新生代用：G1 老年代用：G1）



##### 类加载过程
类加载过程
1. 查找.class文件
* Bootstrap ClassLoader 从JAVA_HOME/lib根据全类名查
* ExtClassLoader（继承Classloader） 从JAVA_HOME/lib/ext根据全类名查
* AppClassLoader（继承ExtClassLoader） 从项目Classpath根据全类名查
2. 解析.class(二进制)，将.class的信息保存在方法区
3. 生成一个Class对象，保存在对象实例池
4. 在方法区，为类的静态变量分配空间（赋默认值：0,null,0L,false）
5. 初始化执行，顺序如下：
    * 静态变量、静态代码块（先执行父类，若在同一个类，则按顺序执行）
    * 成员变量、成员代码块（先执行父类，若在同一个类，则按顺序执行）
    * 构造器（先执行父类，若在同一个类，则按顺序执行）
    
##### 如何查看JVM内存情况？
1. 主动型
* 首先通过top命令获取到jvm的pid
* 使用jmap命令生成dump文件
```bash
#test.dump为dump文件名，1246为jvm的pid，这些都根据实际情况来传参
jmap -dump:format=b,file=test.dump 1246
```
* 进入java/bin目录下，打开jvisualvm工具。选择 文件->装入，将文件类型改为堆Dump，选择test.dump文件即可。
* 也可以选择jprofile工具（需要下载）

2. 被动型
* 当JVM内存溢出时，会自动生成dump文件。（需要-XX:+HeapDumpOnOutOfMemoryError该参数打开）
```bash
#查看dump文件生成位置
java -XX:+PrintFlagsInitial | findstr HeapDumpPath
```
* 取到dump文件后，通过jvisualvm工具分析即可。


###### JVM调优操作
参考：[https://blog.csdn.net/weixin_43238110/article/details/93793357](https://blog.csdn.net/weixin_43238110/article/details/93793357)
**查看当前启用的垃圾回收器类型**

```bash
#查看所有JVM参数
java -XX:+PrintFlagsInitial

#查看当前使用的垃圾回收器
java -XX:+PrintCommandLineFlags -version

#查看垃圾回收器启用情况
java -XX:+PrintFlagsInitial|findstr Use.*GC
```
**一般的垃圾回收器搭配&如何选择垃圾回收器**
1. 串行收集器：Serial（yong区）+ SerialOld（old区）
对应参数：
-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:+UseSerialGC
    > 最古老的垃圾收集器，单个GC线程，GC时会阻塞用户线程。
    > 适合：单核CPU或者小内存，单机程序
    
2. 并行收集器：ParNew（Yong） + SerialOld（old）**（已被废弃）**
对应参数：
-XX:+UseParNewGC
    >很多java虚拟机运行在server模式下新生代的默认垃圾收集器。
    >多线程GC，但仍然会阻塞用户线程。

3. 并行收集器：ParallelScavenge（Young） + ParallelOld（old）
对应参数：
-XX:+UseParallelGC（同时会激活-XX:+UseParallelOldGC参数）
    >ParallelScavenge提供了一种自适应调整策略，会收集系统性能监控信息，尽量让GC时间占JVM运行时间越少，提高系统吞吐量。
    >吞吐量=用户线程运行时间/（GC线程运行时间 + 用户线程运行时间）
    >适合：多CPU，后台计算型应用
    
4. 并发标记清除收集器：CMS **（1.9后被废除）**
对应参数：
-XX:+UseConcMarkSweepGC（同时会激活-XX:+UseParNewGC参数）
    >是一种以获取最短回收停顿时间为目的的收集器。适用于互联网站或者B/S系统的服务器上。
    >ParNew（yong）+CMS（Old）+SerialOld收集器的组合，Serial Old将作为CMS出错的后备收集器。
    >适合：多CPU，追求低停顿时间，快速响应如互联网应用
    >jdk1.7或更低、jdk8内存较低（低于4G）时可选择CMS。
    
5. G1收集器
对应参数：
-XX:+UseG1GC
    >从1.7版本之后就开始有的垃圾回收器。
    >G1意为“Garbage First”，即垃圾优先，哪一块垃圾多先清理那一块。
    >特点为：并发并行（）、没有内存碎片（基于标记整理算法）、可预测的停顿（STW）
    >适合：内存较大（8G以上）、多CPU的服务器



#### 分布式中间件
##### 分布式系统有哪些组件？
* 网关（Gateway）
* 微服务应用（Microservice）
* 消息队列（Message broker）
* 数据库（DB）
* 分布式缓存
* 分布式锁
* 分布式事务

通过以下中间件实现：Spring Cloud APP、Nginx、Zookeeper、RabbitMQ、Kafka、Netty、Dubbo等。


###### Zookeeper的应用场景

###### Kafka的应用场景


##### 网关
###### nginx的原理及配置

##### 分布式应用

###### 企业级常见架构
* SSM（Spring、SpringMVC、Mybatis）
* SpringBoot、Dubbo、Zookeeper
* SpringCloud
###### 什么是UMP系统
UMP系统是由阿里巴巴提出的一套云数据库解决方案。 
用到的开源组件包括：
* mnesia（分布式数据库管理系统）
* LVS（Linux虚拟服务器）
* RabbitMQ（消息队列服务器）
* Zookeeper（协同工作系统）

###### springcloud应用有哪些组件
* Eureka（服务注册与发现）
* Ribbon（负载均衡，在RestTemplate上加@LoadBalance）
* Feign（负载均衡）
* Hystrix（熔断器）
* Zuul（网关）
* Config（配置）

###### 什么是幂等性？如何保证幂等性？
幂等性满足如下条件：
1. 请求后对资源没有副作用；（如select操作）
2. 第一次请求的时候对资源产生了副作用，但是以后的多次请求都不会再对资源产生副作用；

保证幂等性的方法：
1. 请求被处理之后，有地方将结果ID保存起来（例如支付请求，支付完成后将订单ID与支付请求关联起来）
2. 请求被处理之后，有地方将结果状态保存起来（例如支付请求，支付完成后将订单状态改为“已支付”）

###### Eureka Client调用Server的服务的流程 
Eureka Server启动时，会注册信息到Registry（注册中心）；
Eureka Server会定期向注册中心发送心跳信息（每30s），表明自己可用；
Eureka Server发送心跳的同时，会获取最新的注册表信息；
因此，集群里可用的Eureka Server都维护着一张注册表（虽然同一时间内注册表数据可能不一致）
Eureka Client第一次调用服务时，会先从Registry（注册中心）获取服务提供者地址（注册表），并缓存到本地；然后取其中一个Server进行调用。下次调用则可直接调用那个Server的服务；
Eureka Client也会定期去Server端更新注册表；
当注册表中Eureka Server有多个时，Eureka Client会通过 Ribbon 自动进行负载均衡。
当Client发现调用的Server宕机时，Client会重新从本地的注册表中取新的Server调用地址，并调用。

###### Eureka服务调用失败后，有哪些处理方案
* 熔断（默认状态下，当某个服务接受的20个请求里有50%都失败时，触发熔断，再请求该服务会直接返回失败，直到5s后，重新检测是否该打开该服务）
* 降级（当服务熔断后，客户端调用微服务失败，此时客户端自己准备一个Fallback函数，返回一个缺省值或者报错）
* 限流（）
* 排队 
###### Eureka Client的心跳机制 & Eureka Server（注册中心）的剔除机制、自我保护机制
* 心跳机制：client每30s向server发送心跳数据
* 剔除机制：server一定时间内（默认90s）没有接收到心跳数据，则认为该client已下线，会从自己的缓存中移除该client实例的信息
* 自我保护机制：
    * 触发开启：server检查15分钟以内所有Eureka实例的正常心跳比，若低于85%，开启自我保护模式
    * 开启状态下：
        * 发现长时间没发送心跳的client，也不会对其进行剔除；
        * 仍然能接收client的注册，但不会同步到其他server中；
        * 待网络正常后，才将client的注册信息同步到其他server中。



###### Eureka启动一个服务，客户端是怎么从注册中心发现这个服务的，流程说一下
Eureka Client在注册的同时，会启动一个轮询，该轮询会定期从注册中心获取其他服务的信息（IP、port、实例id等），并缓存起来；
调用服务时便会直接从缓存中获取服务的信息。
调用方法：
1. Ribbon参与时，根据spring.application.name：http://eurakaclientsample1/sample/getData
2. Ribbon没有参与时，根据IP+端口：http://localhost:10000/sample/getData

如何让Ribbon参与？在RestTemplate上添加@LoadBalance注解。


###### zookeeper和eureka的区别，以及cap原则

![aa7e9dca8dc36f75a41d3ea2180285af.png](en-resource://database/1110:1)

CAP原则：
* Consistency（一致性）：分布式系统中每个节点中的数据是否总是一致
* Availability（可用性）：分布式系统中，部分节点挂掉了，这个集群是否还能使用
* Partition tolerance（分区容错性）：因某些原因，导致某些机房上部署的系统与其他系统不能通信（不连通），则这些机房便形成了“分区”。分区容错性便是指如果形成了“分区”，如何保证集群的一致性和可用性。

若要满足”分区容错性“，办法是将不同机房中的数据备份到其他机房的节点上。这样数据分布在各个机房中，某个机房挂了，该数据还有副本提供访问；但这样会带来一致性问题。

若要满足”一致性“，每次写操作后，要等待其他节点全部写成功，然后才能读；但这样又会带来可用性问题。

因此，分布式系统一般只能满足CAP中的两个原则。而分区容错性又是必须的，所以一般分布式系统都是再C和A中权衡。

eureka -->AP，即高可用，但不满足一致性
***如何体现是AP？***
Eureka Server每个节点都是平等的，每台Server都维护着Server信息注册表，集群中只要有一台服务Server没有宕机，集群也是可用的；

zookeeper -->CP，即数据一致，但不满足高可用
***如何体现是CP？***
zookeeper server集群至少需要3台服务器（leader选举算法需要）。
zookeeper server集群中的节点分为leader和follow节点。
当leader宕机时，集群需要重新选出leader，此时的集群暂时不可用。

###### cas算法

##### 消息队列
###### rabbitmq有哪些组件，项目中怎么用的，为什么这么用
主要有生产者、消费者、队列、还有交换机。

用法：
1. 异步。可以将函数调用中某些非关键操作异步化。
2. 解耦。当发现某个函数以后可能会发送别的消息到其他系统时，可以用消息队列的模式设计。

##### 分布式数据库

###### 1.为什么需要分布式数据库？分布式数据库的优点有哪些？
    当数据库遇到以下问题，便要考虑对数据库进行扩展：
    1.容量不足
    2.性能变差

    扩容的方案：当遇到以上问题，可以通过以下方式解决：
    1.升级服务器的CPU、硬盘、内存等方式解决（这种方式称为scale-up）。
    2.采用分布式数据库（这种方式称为scale-out）

    采用分布式数据库的优点：
    灵活，方便，上限高
    
    
###### 2. 什么时候该分库分表？
    当单表数据量达1000w或100G时
    
###### 3. 有哪些分库分表的方法？

**分库分表常用中间件：**
sharding-jdbc（当当）
Atlas（360）
Cobar（Alibaba）

两种方式：**垂直切分**和**水平切分**
    
   垂直切分：
 
   （1）垂直分库：将一个数据库切分为多个数据库。所有表也被分类到不同的数据库里。在分类时，将关联度低的表存储到不同的数据库中。
  （2）垂直分表：对某个字段太多的表进行拆分，拆分成两个甚至多个表，其中每个表只有部分的字段。
   
   优点：
   解决业务层面的耦合，业务清晰；
   缺点：
   部分表无法join；
   需要处理分布式事务；
   仍然存在单表数据量太大的问题。
   
   水平切分：
   
   （1）库内分表：当某个单表数据量太大时，拷贝多个该表（有同样的列），将这些数据按某种条件分布到这些表中，从而使单个表的数据量减少。
   
   （2）分库分表：将单表的数据库分到其他机器的表中（与该单表有同样的列）。
   
   优点：
   减少单表的数据量；
   应用端改造较少？
   缺点：
   难以保证事务一致性；
   跨库的关联查询性能较差；
   
###### 4.水平切分后，同一张表的数据会被分到多个库/多张表中。有哪些数据分片的规则？
   
   
   1.根据时间区间或ID区间区分。
   例如，按时间区间区分，将数据分为历史数据和热点数据，即“冷热数据分离”。业务功能上只提供热点数据的查询。
   
   优点：易于扩展，当想对集群扩容时，只要增加机器，无需对其他分片的数据进行迁移。
   缺点：热机会被频繁读写，冷机则很少被查询，导致资源的浪费。
   
   2.根据数值取模
   采用hash取模的方式，将数据平均分到不同的表中。
   
   优点：
   不易出现热点数据和并发访问的瓶颈；
   缺点：
   若集群想要扩容时，需要对分片的数据进行迁移（用一致性hash算法可避免该问题）；
   
###### 5.分库分表带来的问题

1. 分布式事务
当在一个事务中更新数据时，可能需要同时对不同库的不同表进行更新，此时会面临跨库事务的问题。

解决方案：XA事务、两阶段提交。

2. 跨节点join查询
不同库中的表不能再进行sql join查询了。

解决方案：

（1）全局表：一些大部分表都会用到的表（字典），为了避免跨库join查询，可以在每个数据库都保存一份这个表。

（2）字段冗余，直接避免sql join查询；

（3）数据组装：分开查询，并在代码层面对数据进行组装；

（4）ER分片：将有关联关系的表放到同一个分片；
3. 跨节点分页、排序问题

4. 分库分表需要单独设计全局主键。常见主键生成策略：
（1）UUID（32个16进制字符，即0-f）；
（2）专门创建一个生成主键的表。
（3）snowflake分布式自增ID算法。

5. 数据迁移、扩容问题
##### 缓存
###### redis常用数据类型及使用、缓存雪崩及缓存穿透相关解决方案
* string(key-value)，可保存字符串和数字
    * 增/改
        * 普通增 SET key value
        * 设置过期时间 SETEX key seconds value
        * 增加多对键值对 MSET key value key value...
        * 自增一 INCR key
        * 自增N INCRBY key increment
        * 自减N DECR key
    * 删
    * 查
        * 普通查 GET key
        * 查子字符串 GETRANGE key start end
        * 返回多个值 MGET key key ...
* hash(哈希表)
    * 增
        * 往哈希表插入键值对 HSET key field value
        * 插入多对键值对 HMSET key field value field value...
        * 自增N HINCRBY key field increment
    * 删
        * 删除键值对 HDEL key field field ...
    * 查
        * 查某个键对应的值 HGET key field
        * 查所有键值对 HGETALL key
        * 查所有键 HKEYS key
        * 查所有值 HVALS key
* list（数组）
    * 增
        * 插入多个值到列表头部 LPUSH key value value ...
        * 插入多个值到列表尾部 RPUSH key value value ...
        * 通过索引修改值 LSET key index value ...
    * 删
        * 移出并获取第一个元素 LPOP key
        * 移出并获取最后一个元素 RPOP key
    * 查
        * 查找数组中第i个元素 LINDEX key i
* set（集合）
    * 增
    * 删
    * 查
* zset（有序集合）
    * 增
    * 删
    * 查

###### 1.缓存雪崩
缓存雪崩是指，如果所有key的失效时间一致，便会造成在某一时间段所有key失效；此时查询请求会直接去到数据库中。若请求太多甚至会使数据库挂掉。
处理方法：为key的失效时间加个随机值。

###### 2.缓存穿透
缓存穿透是指，用户不断查询缓存中没有的数据，导致请求直接去到数据库中。
处理方法：
1.增加参数校验，不符合规格的入参直接返回报错。
2.Redis自带的布隆过滤器。

###### 3.缓存击穿
与缓存雪崩类似，缓存击穿是有一个Key并发特别大，当该key失效时，大量的请求直接去到数据库，拖垮数据库的性能。
处理方法：
1.设置热点数据永远不过期。
2.加上互斥锁。



#####  分布式锁
###### 1.什么时候需要分布式锁
分布式锁的使用在分布式系统中较为常见，当某个变量需要被不同机器上部署的系统共享使用时，就需要用到分布式锁来控制共享变量的访问，尽量做到不出现数据一致性问题。
###### 2.如何实现分布式锁？

1. 基于数据库实现分布式锁；
创建一个表，表id即为锁。插入一条数据就是一次获取锁的操作。
利用了主键唯一的特性，当已获取了id为1的锁后，再次获取（即插入id=1的数据）会报错，通过此机制实现分布式锁。

2. 基于缓存（Redis等）实现分布式锁；
使用redisson框架。

3. 基于Zookeeper实现分布式锁。
使用zk的临时节点（set -e /lock/...）。
临时节点是当session关闭后，节点会被删除。因此可以当做分布式锁来用。


##### 分布式事务

###### 1.有哪些事务的解决方案？有哪些分布式事务的解决方案？
**单数据库事务：** 每种商用数据库基本上都有自己的事务框架。

**分布式事务：** 多个数据库共用一个事务，全部操作成功则提交事务，若其中一个失败则全部需要回滚。

有以下几种实现分布式事务的模式：

强一致性（严格保证ACID原则）
* 2PC（两阶段提交）
* 3PC（三阶段提交）
* TCC（）

最终一致性（不保证一直保持ACID原则，但最终总会达到ACID）
* 本地消息表
* 消息事务（MQ）
* 最大努力通知


先从强一致性的模式开始说。

**2PC模式**
原理：

假设某个函数需要向N个数据库插入数据，会经历以下两个阶段。

准备阶段（prepare）：
各个数据库开启自己的事务，执行插入语句；
执行完后，不提交，而是通过XA接口告诉事务管理器已准备好(prepare)；

提交阶段（commit）：
当所有数据库已准备好（prepare），事务管理器才通过XA接口告诉所有数据库，可以提交事务（submit）；
反之，若有某个数据库没有返回“准备好（prepare）”，则事务管理器告诉所有数据库，需要回滚事务（rollback）。


优点：
1. 能保证强一致性
2. 现实分布式事务的耗时相对比较少（只需要一次prepare、一次commit即可） 

缺点：
1. 同步阻塞资源。分布式事务开启期间会锁住资源，导致其他事务需要等待。
2. 单点故障。当某节点参与分布式事务时突然宕机，没提交prepare，则其他节点都会处于等待commit状态。
3. 数据不一致。当事务管理器接收到所有prepare，并返回submit（可以提交）时，部分节点宕机，则会导致实际上有的事务没有被提交，导致数据不一致。

**3PC模式**
原理：

在2PC的基础上，增加了询问阶段；且增加了“超时没接到回复则默认失败”的机制。

**询问阶段（CanCommit）：**
【事务管理器】
事务管理器向各个参与者发出CanCommit的询问，问是否可以顺利执行事务；
【参与者】
参与者觉得可以，则返回yes；不可以则返回no。


**预提交阶段（PreCommit）：**

【事务管理器】
两种情况。
1. 事务管理器接收到所有参与者的回复都是yes，则向所有参与者发送PreCommit消息；

2. 有参与者回复no，或者等待参与者消息超时，则向所有参与者发送abort消息（中断事务）；

【参与者】
1. 接收到PreCommit：就会像2PC的准备阶段一样，开启事务，执行SQL语句，并将undo和redo记录下来；
参与者执行完后，执行成功则返回preCommit ACK；执行失败则返回no；

2. 接收到Abort：执行事务的中断。

3. 超时没接收到事务管理器的回复：执行事务的中断。


**提交阶段（doCommit）：**
【事务管理器】
当所有参与者都返回ACK，才进入到该阶段。事务管理器向所有参与者发送doCommit请求。

【参与者】
接收到doCommit请求，正式提交语句，并释放占用资源。
提交完后，向事务管理器返回doCommit ack；

若超时没有收到doCommit请求，参与者也会提交语句，并释放占用资源，返回doCommit ack；

【事务管理器】
接收到所有ack后，完成事务。

若没有接收到所有ack，则向所有参与者发送abort消息（中断事务）；

【参与者】
收到abort消息后，使用undo日志回滚事务，回滚完后释放所有资源；
回滚完后，返回ack

【事务管理器】
接收到所有ack后，完成回滚。


>2PC模式、3PC模式最终都有可能因为宕机、网络问题，导致数据不一致的情况。此时只能用人工补偿（比如SQL脚本检查）去达到最终一致性了。
>2PC有相应的支持（XA），3PC没有或者不常用。


**XA模式（2PC的实现）**
![86ff10ed2ada3384c314139b78280615.png](en-resource://database/961:1)
XA模式将系统大致分为两个角色：事务管理器(TransactionManager)，本地资源管理器（一般指数据库，以下均称为数据库）。
数据库自己可以提供事务，因此，若只对一个数据库进行读写操作的话，只需要使用自己数据库的事务功能即可；
但当需要对不同数据库进行操作时，便需要有事务管理器来协调和管理事务。

* XA提供接口来支持事务管理器与数据库之间的交互。
* 商用数据库基本都实现了XA接口。


**TCC模式**
适合分布式事务中有不提供事务机制的系统参与的情况（例如文件系统、Redis等）。
TCC也是强一致性，大概原理是，当某个系统执行失败，需要回滚时，这个回滚的实现由开发者通过代码来完成。

原理如下。
* T for Try（尝试机制）：
增加一种预提交的状态，先将资源冻结，或将状态设置为“进行中”；
    >这阶段就是开启事务，并执行sql，但不提交；文件系统则是新值内容。

* C for Confirm（提交）：
当所有Try操作成功后，则TCC框架会将所有Try操作冻结的资源释放，或将状态设置为“已成功”；
    >这阶段就是直接在数据库commit事务，文件系统则是保存文件。

* C for Cancel（取消）：
若其中一个Try操作失败，则TCC框架会取消所有冻结的资源，或将状态设置为“已失效”
    >做一些逆操作。数据库：将原来的值置回去；文件系统：把原来的内容贴回去。



**消息队列（MQ）+本地事件表模式**
假设有以下情况：
有一个业务需要按以下步骤进行：A->B->C。
其中服务器a负责A，b负责B，c负责C；
这些服务器都会维护一个事件表（同一数据库里的一张表），还有一个定时任务处理器（例如quartz）；
步骤A、B、C就是根据事件表和MQ中的事件驱动，一步一步把流程走完。

一开始请求进来，调用服务器a完成A步骤；
【服务器a】
成功：
1. 服务器a完成并提交A步骤到数据库，并将“A步骤已完成”这个事件写到本地事件表中（有一个事件ID、时间、事件类型）；
2. 定时任务器会将该事件发送到MQ上，并修改本地事件表中事件的状态。
至此服务器a工作完成。

失败：则直接返回失败。

【服务器b】
成功：
1. 服务器b的定时任务器会监听MQ上的“A步骤已完成”事件；发现有，则写到自己的事件表中；
2. 定时任务器还会监听自己事件表，如果有“A步骤已完成”事件，则开始调用B步骤的逻辑；
3. 服务器b完成并提交B步骤到数据库，并将“B步骤已完成”这个事件写到本地事件表中（有一个事件ID、时间、事件类型）；
4. 定时任务器会将该事件发送到MQ上，并修改本地事件表中事件的状态。

至此服务器b工作完成。

失败：
1. 服务器b若完成不了步骤B，也需要将“B步骤完成失败”这个事件写到本地事件表中（有一个事件ID、时间、事件类型）；
2. 定时任务器会将该事件发送到MQ上，由服务器a来监听该事件并回滚。

【服务器c】
成功：参考b

失败：参考b。也会发送“C步骤完成失败”的事件到MQ；B监听到后回滚并发送“B步骤完成失败”的事件到MQ，如此类推...

>1. 该模式适合无需同步完成的任务，所有步骤都是异步进行的，因此不能达到强一致性，但理论上能达到最终一致性。
>2. 为了避免重复消费，保证幂等性，应该为每个分布式事务都分配一个ID。这样一旦出现重复消费，在插入自己的本地事件表的时候就会报错。
>3. 每个服务器的本地事件表跟自己其他的业务表均在同一数据库中，因此若步骤完成失败了，就可以直接回滚两个表的操作。


**可靠消息服务模式**
与“本地事件表模式”相似，只不过将所有服务器的事件表都通过一个“可靠消息服务”来维护。







###### 2. Java、Spring中，事务、分布式事务的运用？

Java事务框架：
* JDBC事务（仅为单个数据库提供事务支持）
* JTA事务（可理解为Java版XA规范；支持多个数据源的回滚：JDBC连接、JDO、JMS、EJB等）
    > JTA只是一套接口，其实现有：atomikos、JOTM
* JDO事务
* JPA事务
* JMS事务
* Hibernate事务
* Mybatis事务
* Spring事务
* LCN
* ByteTCC
* SeaTa

常见分布式事务框架：
|框架|TCC模式|XA模式|AT模式（2PC的改良版）|saga模式|MQ|原理|
|---|---|---|---|---|---|---|
|Atomikos|---|✔|---|---|---|两阶段提交（2pc）|
|LCN|✔|---|---|---|---|
|ByteTCC|✔|---|---|---|---|
|Seata|✔|✔|✔|✔|---|



#### 数据库

##### 常见SQL题目
###### 求每个学生分数最高的科目
表：dyz.t_score(id,score,name,subject)
```sql

--用子查询先求出每个学生的最高分
select t1.* from dyz.t_score t1,
(select max(score) score,name from dyz.t_score group by name) t2 where t1.name = 
t2.name
and t1.score=t2.score;
```
###### 求每个学生的语文、数学、英语成绩，在同一行中显示（行转列）
```sql
select name,
max(case subject when '语文' then score else null end) '语文',
max(case subject when '数学' then score else null end) '数学',
max(case subject when '英语' then score else null end) '英语',
 from dyz.t_score group by name;
```
##### 数据库索引一般用什么数据结构？数据一般用什么数据结构？
关系型数据库，索引一般用B+树，数据一般用B+树；
为什么用B+树？
1. 时间复杂度需要Logn ： AVL树、B树、B+树；
2. 树高需要更低：B树、B+树；
3. 非叶子节点不存数据（每一页可存更多节点）、叶子节点间有指针（方便扫描遍历）：B+树

mongodb索引用B树，数据用文件存储？



##### Mysql有哪些索引？
普通索引
唯一索引（索引的值必须唯一，可以为null）
主键索引（索引的值必须唯一，但不能为null）
全文索引（只有MyISAM存储引擎支持）
组合索引
空间索引

##### 什么是聚簇索引、非聚簇索引？
聚簇索引：数据库表中数据的物理顺序与键值的逻辑（索引）顺序相同；索引与数据保存在一起（主键索引就是一个聚簇索引，若无定义主键，InnoDB会隐式定义一个主键。B-树、B+树）
非聚簇索引：索引与数据分开保存（索引树的叶子节点是数据的ID（InnoDB）或数据的物理地址（MyIsam），取得后还要根据结果再去查询）

Mysql的InnoDB引擎用的就是聚簇索引。用.frm文件保存创建表的语句，用.idb文件保存表的索引和数据；
MyIsam引擎则用非聚簇索引。用.frm文件保存创建表的语句，用.MYD文件保存表的数据，用.MYI文件保存表的索引；


##### 什么是覆盖索引？
覆盖索引指的是在一次查询中，如果一个索引包含或者说覆盖所有需要查询的字段的值，我们就称之为覆盖索引，而不再需要回表查询。
而要确定一个查询是否是覆盖索引，我们只需要explain sql语句看Extra的结果是否是“Using index”即可。

##### Mysql在执行sql更新时，底层的流程是怎么样的
1. 客户端进程（驱动）与Mysql服务端进程建立连接（进程间通信）
2. 客户端发出SQL请求，服务端分出线程处理请求
3. 缓存：服务端线程先查缓冲池，命中则直接返回
4. 解析器、优化器：没命中，则通过解析器、优化器生成执行计划
5. 执行器：调用存储引擎去执行（下面以InnoDB为例）
6. InnoDB存储引擎：从硬盘取数据页到缓存池，再在缓存池内从数据页中查找需要的数据，查不到则继续从硬盘取下一个页到缓存池，继续搜索。
7. InnoDB存储引擎：若查到，先将旧数据保存到undo缓存中（以防需要回滚）
8. InnoDB存储引擎：在页中对数据进行修改
9. InnoDB存储引擎：再将修改后的数据保存到redo缓存中（以备数据恢复）
10. InnoDB存储引擎：事务提交后，将redo缓存写回redo日志（硬盘）和binlog日志（硬盘）中，最后在redo日志中写入本次修改在binlog的位置，并添加上commit标记
11. InnoDB存储引擎：通过InnoDB的后台线程将修改后的数据定时刷新回硬盘

（另有说法：8应在10之后完成，即应先写redo log，再在页中对数据进行修改）

##### mysql事务隔离级别、存储引擎，索引结构和类型
事务隔离级别：
* 读未提交（修改：排他锁；读取：不加锁。但修改后，事务未提交便释放锁，导致脏读：其他事务可读取到未提交的修改）
 解决方法：事务提交后再释放排他锁。
* 读已提交（修改：排他锁；读取：不加锁。但读取时，允许其他事务修改数据，导致不可重复读：即事务A先读取了数据，但事务B之后立即将数据修改了，导致事务A第二次读取时发现数据不一致）
解决方法：
    1. 针对需要加锁的操作（当前读）：数据读取时加共享锁。使数据读取时不能被修改。
    2. 针对不需要加锁的操作（快照读）：MVCC
* 可重复读（修改：排他锁；读取：共享锁。）
发生幻读的例子：
    1. select * from t where a=1时 查出一条记录 a:1 b:2
    2. 其他事务往t表中插入1条a:1 b:3
    3. 若再查询select * from t where a=1时 此时会查出两条记录 a:1 b:2 | a:1 b:3
    4.第两次查询发现有新内容，便称为幻读
 解决方法：
    1. 针对需要加锁的操作（当前读）：数据读取时加间隙锁
    2. 针对不需要加锁的操作（快照读）：MVCC

* 串行读
    所以事务均以串行执行，这样就不会有并发问题。

***四个隔离级别：***
* 读未提交（会有脏读）
* 读已提交（会有不可重复读）
* 可重复读（会有幻读）
* 串行读（一次只执行一个事务，没有并发事务就不会有上面的问题，但效率很慢）

Mysql默认的隔离级别是可重复读（select @@transaction_isolation）；
通过多版本并发控制（MVCC）达到可重复读；
通过并+间隙锁（Next-key Locking）防止幻读。

|||读未提交（Read Uncommitted）|读已提交（Read Commited）|可重复读（Repeatable Read）|可串行化（Serializable）|
|---|---|---|---|---|---|
|SQL|条件|
|select|相等|无锁| consistent read（MVCC）|consistent read（MVCC）| 共享锁(share lock)|
|select|范围|无锁| consistent read（MVCC）|consistent read（MVCC）| 共享间隙锁（share next-key）|
|update|相等|独占锁(exclusive lock)| 独占锁|独占锁| 独占锁|
|update|范围|独占间隙锁（exclusive next-key）| 独占间隙锁|独占间隙锁| 独占间隙锁|
|insert| - |独占锁(exclusive lock)| 独占锁|独占锁| 独占锁|
|replace|无键冲突|独占锁(exclusive lock)| 独占锁|独占锁| 独占锁|
|replace|有键冲突|独占间隙锁（exclusive next-key）| 独占间隙锁|独占间隙锁| 独占间隙锁|
|delete|相等|独占锁(exclusive lock)| 独占锁|独占锁| 独占锁|
|delete|范围|独占间隙锁（exclusive next-key）| 独占间隙锁|独占间隙锁| 独占间隙锁|
|select...from lock in share mode|相等|共享锁（share lock）|共享锁|共享锁|共享锁|
|select...from lock in share mode|范围|共享锁（share lock）|共享锁|共享间隙锁（share next-key）|共享间隙锁|
|select...for update|相等|独占锁(exclusive lock)| 独占锁|独占锁| 独占锁|
|select...for update|范围|独占锁(exclusive lock)| 共享锁（share lock）|独占间隙锁（exclusive next-key）| 独占间隙锁|

***数据库的并发场景：***
* 读读（无需并发控制）
* 读写（可能会遇到脏读、不可重复读、幻读的问题）
* 写写（可能会遇到第一类更新丢失、第二类更新丢失的问题）

而读又分为两种：
* 当前读
   需要对读取的记录加锁的操作。包括：
    * 加共享锁（读锁）：select lock in share mode
    * 加排他锁（写锁）：select for update ; update, insert ,delete；
* 快照读
    不需加锁的select操作就叫快照读。

其中，MVCC解决 快照读-写 遇到的并发问题；
间隙锁解决 当前读-写 遇到的并发问题；
通过悲观锁（以排他锁实现）解决 写-写 遇到的并发问题。


###### MVCC原理
参考：
https://www.jianshu.com/p/29ca075763f0
https://www.pdai.tech/md/db/sql-mysql/sql-mysql-mvcc.html
***一种不需要加锁便可解决读写时遇到的并发问题的方案。***

MVCC就是为了不加锁但同时还能解决读写时遇到的并发问题。这里的读指的是快照读。

要知道，读的时候若不加锁，便会出现不可重复读、幻读的问题。
MVCC就是通过行隐藏字段、Undo日志、ReadView来实现快照读，从而完成“不加锁解决读写问题”的任务的。

InnoDB的行数据有两个重要的隐藏列：
* DB_TRX_ID 最近一次修改该行数据的事务ID，有的也把这个称为“创建版本号”
* DB_ROLL_PTR 一个指针，指向该行对应的undo链，有的也把这个称为“删除版本号”

快照中保存的以下信息：
* trx_list：事务1执行快照读那刻系统正活跃的事务ID
* up_limit_id：trx_list列表中事务ID最小的ID
* low_limit_id：trx_list列表中下一个事务ID，也就是目前已出现过的事务ID的最大值+1

MVCC在隔离级别为“读已提交（Repeatable Committed） ”下产生不可重复读的原理，如下图：


![863566e7e6aeb5d7d8e33048681d18e9.png](en-resource://database/965:1)

MVCC在隔离级别为“读已提交（Repeatable Committed） ”下不会产生脏读的原理，如下图：
![1df65677047c1c49a6c46d341b24762a.png](en-resource://database/967:1)

MVCC在隔离级别为“可重复读（Repeatable Read） ”下不会产生“不可重复读”的原理，如下图：
![e179067941bcbd34fdfaf129a897d878.png](en-resource://database/969:1)

InnoDB 的MVCC在隔离级别为“可重复读（Repeatable Read） ”下不会产生“幻读”的原理，如下图：
![96739502cf857068a84aa2f700d64aeb.png](en-resource://database/971:1)


##### mybatis
###### 调用sql的原理
1. 通过@MapperScan(basePackages = "sample.jdbc.mapper")，将所有Mapper接口纳入Mybatis的管理；
2. 调用Mapper，有以下几种情况：
* 通过Spring调用，则直接Autowired一个Mapper变量即可；
* 通过Session调用
```java
InputStream inputStream = Resources.getResourceAsStream("SqlMapConfig.xml");
// 构建sqlSessionFactory
SqlSessionFactory sqlSessionFactory = new 
SqlSessionFactoryBuilder().build(inputStream);
// 获取sqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();
Map<String,Object> parameters = new HashMap<String,Object>();
parameters.put("testid","1");
TestVo test = sqlSession.selectOne(
"sample.jdbc.mapper.TestMapper.getTestById",parameters);

```

3. DefaultSqlSession->Configuration->
MapperRegistry->MapperProxyFactory
最后是由MapperProxyFactory根据全类名生成一个代理类。


###### Mybatis如何实现分页？
* 直接在SQL中加入分页语句
* 通过mybatis的插件机制，写一个拦截器，拦截需要分页的函数，拦截成功后会自动在sql中添加分页语句。
* 依赖pagehelper，pagehelper原理跟上面一样。

###### mybatis的一级缓存、二级缓存
一级缓存：作用域为session。通过HashMap存储。session关闭后，缓存清空；
```java
         SqlSession sqlSession=sqlSessionFactory.openSession(true);                //true后是自动提交       
         String statement="procedure.getUser";
         CUser cuser=sqlSession.selectOne(statement, 1);
         System.out.println(cuser);
         //再跑一次
         cuser=sqlSession.selectOne(statement, 1);
         System.out.println(cuser);
         //看日志会发现只查询了一次数据库
```
二级缓存：作用域为Mapper。通过HashMap存储。session提交或关闭后，一级缓存的数据会保存到二级缓存中。
```java
         SqlSession sqlSession1=sqlSessionFactory.openSession(true);                //true后是自动提交     
         SqlSession sqlSession2=sqlSessionFactory.openSession(true);                //true后是自动提交     
         String statement="procedure.getUser";
         CUser cuser=sqlSession1.selectOne(statement, 1);
         System.out.println(cuser);
         //再跑一次
         cuser=sqlSession2.selectOne(statement, 1);
         System.out.println(cuser);
         //看日志会发现只查询了一次数据库
```
如何开启&关闭？
一级缓存：默认开启；
```xml
<!-- mybatis.cfg.xml-->
<setting name="localCacheScope" value="SESSION"/>
<!-- 
SESSION：开启;
STATEMENT：关闭；
-->
```



二级缓存，满足以下几点：默认不开启
* 一级缓存开启
* <setting name="cacheEnabled" value="true"/> 
* 去mapper.xml中配置使用二级缓存：<cache></cache>
* 我们的POJO需要实现序列化接口

一级缓存失效的场景：
* sqlsession不同；
* sqlsession相同，但查询没有的数据；
* sqlsession相同，但两次查询之间有增删改操作；（每个增删改标签都有默认清空缓存配置：flushCache="true"）
* sqlsession相同，但手动清除了一级缓存（缓存清空）

###### mysql的动态sql标签

trim | where | set | foreach | if | choose| when |
otherwise | bind

示例：
```xml
<!--if的用法-->
<select id="findActiveBlogLike"
     resultType="Blog">
  SELECT * FROM BLOG WHERE state = ‘ACTIVE’
  <if test="title != null">
    AND title like #{title}
  </if>
  <if test="author != null and author.name != null">
    AND author_name like #{author.name}
  </if>
  </select>
  
  
  <!-- choose when otherwise的用法-->
<select id="findActiveBlogLike"
     resultType="Blog">
  SELECT * FROM BLOG WHERE state = ‘ACTIVE’
  <choose>
    <when test="title != null">
      AND title like #{title}
    </when>
    <when test="author != null and author.name != null">
      AND author_name like #{author.name}
    </when>
    <otherwise>
      AND featured = 1
    </otherwise>
  </choose></select>
```

###### mybatis的关联查询
分为联合查询和嵌套查询。

**联合查询**
一对一时：
<association property="属性名" javaType="全类名">
<id column="id" property="id"/>
<result column="name" property="name"/>
<association/>
一对多时：
<collection property="属性名" javaType="全类名">
<id column="id" property="id"/>
<result column="name" property="name"/>
</collection>

**嵌套查询**
一对一时：<association property="属性名" select="select标签的id"></>
一对多时：<collection property="属性名" select="select标签的id"></>



#### Spring

##### Spring Bean的作用域
* singleton：单例模式（默认）
* prototype：原型模式（每次获取Bean都会新建一个实例）
* request：在一次Http请求中，容器会返回该Bean的同一实例
* session：在一次Http Session中，容器会返回该Bean的同一实例
* global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例

##### ioc和aop说一下
IOC：
重耦合：形容系统、模块或者类之间联系紧密，容易“牵一发而动全身”，某个部分需要改动时会影响到其他部分，是设计不好的一种体现，在Java中就体现在对象与对象之间的关系。
IOC即“控制反转”，通过对象容器去管理对象的注册、初始化以及依赖。对象之间若想建立依赖，只要修改容器的配置即可，而不用去修改源码。

AOP：
面向切面编程，本质上也是为了减轻系统耦合性的一种架构。
有许多业务之外的操作，是在调用一些函数的前后经常需要用到的，比如事务的开启与关闭、写日志等等。
若每次调用都要手动去写这些内容，一会增加工作量，二是当这些操作需要换一种方式去实现的时候，修改的工作量会很大。
AOP通过代理模式，提供了一种“代码织入”的方法。


##### springboot运行原理
1. 自动配置类加载：初始化classpath下 META-INF/spring.factories中已配置的ApplicationContextInitializer、ApplicationListener
2. 配置(yml等)读取类加载：初始化classpath下 META-INF/spring.factories中已配置的 SpringApplicationRunListeners
3. 构造应用上下文环境：Java环境、Spring运行环境、Spring项目运行环境
4. 初始化应用上下文
5. 刷新容器（Ioc容器在这进行初始化）
##### springmvc执行流程



##### Spring事务
###### 如何配置Spring事务
编程式事务（TransactionTemplate）
声明式事务（XML、注解注入）

###### Spring事务是怎么回滚的？

#### 算法
##### 有哪些排序算法？说一下原理以及时间复杂度？

#### 操作系统
##### 什么是自旋锁（spin lock）和互斥锁（Mutex）？
自旋锁：一种非阻塞锁，当线程获取不到一个自旋锁时不会被阻塞，而是一直试图获取。
```java
//类似于以下情况
while(!lock.tryLock()){
  //...
}
```
互斥锁：一种阻塞锁，当线程获取不到锁时会被阻塞，释放CPU时间片；待互斥锁被释放后，该线程才会被激活。

>自旋锁等待开销小，互斥锁等待开销大（需要线程切换）；
>单核机器中，自旋锁在等待时，会一直占用CPU资源，因此一般不用自旋锁；
>多核机器中，若预计等待时间较短，则建议用自旋锁；否则用互斥锁。

#### 其他
对称加密和非对称加密，具体的加密算法
常用shell命令
##### 平常用到哪些设计模式，怎么用的
单例模式
UI组件管理类。

代理模式
客户端调用服务端的代码。

#### 关于省中医的项目
RPC调用的过程
1.以本地调用方式调用服务
2.stub（代理类）将调用方法及参数封装成网络传输的消息（序列化）
3.stub找到服务地址，发送消息
4.server stub（代理类）收到消息，解码（反序列化）
5.server stub调用服务器上的本地服务

RPC框架比较
||RMI|Hessian |Dubbo| SpringCloud(Eureka)|Spring Cloud Alibaba|Dubbox|
|---|---|---|---|---|---|---|
|序列化层|Java序列化|hessian|hessian（默认）、java原生序列化、json|Jackson、FastJson||Java序列化：Kryo、FST Json序列化：Jackson|
|网络层|RMI协议|HTTP协议|Dubbo协议、RMI、Hessian、HTTP、WebService、Memcache、Dubbo Thrift|HTTP协议（RestTemplate）||与Dubbo一样|
|通信|RMI|RMI|mina和netty|嵌入式TOMCAT||嵌入式TOMCAT|
|优缺点|RMI协议不能跨越防火墙|可跨越防火墙，轻量级，支持多种语言（python、.net、c++、Java），功能比较单一|支持多种序列化格式、支持多种网络协议、支持负载均衡，支持服务发现、调度、监控等功能|||当当网推出、扩展Dubbo、支持REST风格调用|

##### Mybatis
Mybatis的架构：
* 接口层
    * 基于传统的Mybatis提供的API（Statement ID）
        原理：通过传递Statement ID以及一些参数给Sqlsession，使用sqlsession与数据库完成交互。
    * 使用Mapper接口
* 数据处理层（核心）
    * 通过传入参数构建动态SQL语句（可了解一下ognl表达式）；
    * SQL语句的执行以及封装查询结果集成List<E>
* 框架支撑层
    * 事务管理机制
    * 连接池管理机制
    * 缓存机制
    * SQL语句的配置方式
* 引导层

${} 与#{}的区别
    ${} 直接插入，会带来SQL注入的问题
    #{} 预编译，会将入参转化为字符串（即加上''）


##### 设计模式
##### Nginx



